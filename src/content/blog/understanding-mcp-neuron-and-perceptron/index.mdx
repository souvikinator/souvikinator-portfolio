---
title: 'How MCP Neurons and Perceptrons Mirror Real Neurons'
date: 2025-05-10T05:30:47+05:30
draft: false
tags: ['Machine Learning', 'Artificial Intelligence', 'Deep Learning']
description: 'Explore how McCulloch-Pitts neurons and perceptrons work, and see how they compare to real neurons in the brain'
image: './cover.png'
---

import Callout from '@/components/Callout.astro'

> [!NOTE]
> **Neuroscientists:** "It‚Äôs all about synapses and neurotransmitters.‚Äù<br />
> **Engineers:** ‚ÄúFascinating! Can we turn that into code?‚Äù

Fast forward to today, it's everywhere in our lives.

Recently, I picked up the book "How Machines Learn" and found myself captivated by how the earliest artificial neurons like the MCP neuron and the perceptron were designed to mimic real biological neurons (to a certain extent). In this post, I‚Äôll break down how these foundational models work, how closely they mirror the brain, and we'll implement it.

## The Real Deal: Biological Neurons

We all know Neurons are cells found in nevrous system and it's main job is to transmit electrical and chemical signals throughout the body.

![Single Neuron Breakdown](./single-neuron-breakdown.png)

### How do neurons work?

1. **Dendrites**: these are like thoundands of tiny antennas, each receive signals from other neurons

2. **Signals**: these are electrochemical signals and one thing to note is each signal has it's importance meaning one signal can be less important than other. Signals can be excitatory (encouraging the neuron to fire) or inhibitory (discouraging it)

3. **Cell body/Soma**: All the incoming signals gather up at the body and it decides whether to fire the signal or not. If the combines importance of the excitatory signal minus the inhibitroy signal exceeds this threshold -> Boom the neuron fires.

4. **Axon & Terminals**: This is like a dedicated output cable, carrying the decision. Axon terminals are like broadcast stations, sending the signal to dendrites of other neurons

### Neuron working analogy

![bar analogy for neuron's working](./bar-analogy.png)

Think of it like a bar with the world's most mathematical bouncer. Let's break down how this party (I mean, neuron ;) works:

1. Every person (signal) has a specific importance value (weight)
2. Normal people count as 1
3. VIPs count as 2 (they're twice as important!)
4. Police/party-poopers count as -2 (they actually work against the party starting)
5. The party only starts when the total "party value" hits a certain threshold

#### **The Basic Party Math**

![bar analogy for neuron's working](./bar-analogy-1.png)

When just one regular person shows up (value = 1), and the threshold is > 1, no party happens. But when two regular people arrive (1 + 1 = 2), boom! We hit the threshold, and the party (neuron) activates!

#### **When Things Get Interesting**

![bar analogy for neuron's working](./bar-analogy-2.png)

Now this is where our bouncer's math gets spicy (just like real-world drama):

**Scene 1**: Two regular college buddies show up $(1 + 1)$, but wait... who's that rolling up in a Mercedes? Oh snap, it's the minister's son and his influencial friend $(VIP = 2)$! Total party value hits $6$ and Party mode: ACTIVATED! üéâ

**Scene 2**: A police officer $(-2)$ shows up after getting noise complaints. But lucky for us, we've got our the minister's son and his equally influential friend $(2 + 2)$.
Even with Officer Party-Pooper, the vibe stays alive because $4 > threshold$.

Diplomatic immunity for the win! (He pulled off an _'Janta hai mera baap kon hai?'_)

**Scene 3**: Plot twist! Turns out he was just pretending to be a minister's son.

Three real police officers $(-2 √ó 3 = -6)$. Even with our regular squad and the influential friend $(total positive = 6)$, the party gets shut down faster than he can say "My dad will hear about this!" Because $6 - 6 = 0 < 4$

Moral of the story? Just like neurons, it's all about balance - and maybe don't lie about being a minister's kid! üòÖ

Just like this bouncer, a neuron:

- Adds up excitatory signals (party people)
- Subtracts inhibitory signals (police)
- Only "fires" (starts the party) when the total hits the threshold
- Stays quiet (no party) when it doesn't

![mcp meme](./mcp-meme.png)

Well that's what McCulloch Pitts Neuron (MCP) Neuron does. It's a super simplified binary version of a real neuron. Read more about the [limitations and differences](#limitations-and-differences) below.

## McCulloch Pitts Neuron (MCP)

![McCulloch Pitts Neuron explained](./mcp-breakdown.png)

Here is how it works:

1. Takes weighted inputs and sums them up
2. Passes weighted sum to the **activation function**
3. Activation function based on threshold produces binary output $1$ or $0$

> Why binary output?
>
> Because back then due to limited understanding of neurons, scientists were under the assumption that neurons were in two state: **Fires** or **Doesn't fire**.
>
> Now we know that Neurons produces spectrum of outputs and there are a lot more elements involved into it and we have more advanced models of neurons.

### Activation function

An activation function is like a decision-maker for a neuron, like the Soma (cell body).

It takes total signal a neuron receives (after adding all of the weighted inputs) and determines what the output should be, which is usually transformed into something useful like 0 or 1, or a number between 0 and 1.

The MCP neuron uses **Step Function** i.e it returns binary output based on the input meeting the given a threshold $Œ∏(theta)$ criteria.

$y$ being the output of the activation function and $u$ being input (total signal/weighted sum) or in other terms $u$ is the output of the weighted sum function.

```math
{\displaystyle y={\begin{cases}1&{\text{if }}u\geq \theta \\0&{\text{if }}u<\theta \end{cases}}}
```

<Callout title="Intuition" variant="intuition">
  <p>
    If you get anxious seeing such mathy fonts, here's a flow diagram to help build intuition:
  </p>

  ![step function flow diagram](./step-function-diagram.png)

</Callout>

This is also used in [perceptron](#perceptron) as we'll discuss further. But the question is what can we do with it?

### Implementing MCP Neuron

Let's implement it in code. We'll use Python to create a simple implementation of the MCP neuron.


<Callout title="Python Implementation: MCP Neuron" variant="example">
  <p>
    This class takes a list of weights and a threshold, computes the weighted sum of the inputs, and applies a step activation function:
  </p>
  ```python
  class MCPNeuron:
      def __init__(self, weights, theta):
          self.weights = weights
          self.theta = theta

      def weighted_sum(self, inputs):
          return sum(i * w for i, w in zip(inputs, self.weights))

      def step_function(self, u):
          return int(u >= self.theta)  # returns 1 if threshold met, else 0

      def activate(self, inputs):
          u = self.weighted_sum(inputs)
          return self.step_function(u)
  ```
</Callout>


### Implementing Logic Gates using MCP

Why are we suddenly talking about logic gates? Well, it turns out MCP neurons can do something pretty neat: they can simulate basic logical operations. This was one of the first practical applications that got researchers excited.

Just by choosing different weights and thresholds, we can make it perform logical operations. Let's see how:

#### The AND Gate

First, let's look at the AND operation:

| Input 1 | Input 2 | Output |
| ------- | ------- | ------ |
| 0       | 0       | 0      |
| 0       | 1       | 0      |
| 1       | 0       | 0      |
| 1       | 1       | 1      |

To make an MCP neuron behave like an AND gate:

- Give both inputs a weight of 1
- Set threshold to 2
- This way, we only get output 1 when BOTH inputs are 1 (1 + 1 ‚â• 2)

![and gate using MCP neuron](./mcp-and.png)

<Callout variant="example" title="Implementing AND Gate">
  <p>
    Here's how we can implement the AND gate using our MCP neuron:
  </p>
  ```python
weights = [1,1]
threshold = 2
andGate = MCPNeuron(weights,threshold)

inputs = [1,1] # try out other inputs
print(andGate.activate(inputs))
  ```
</Callout>

#### The OR Gate

The OR operation outputs true if ANY input is true:

| Input 1 | Input 2 | Output |
| ------- | ------- | ------ |
| 0       | 0       | 0      |
| 0       | 1       | 1      |
| 1       | 0       | 1      |
| 1       | 1       | 1      |

To create an OR gate:

- Keep weights at 1 each
- Lower threshold to 1
- Now we get output 1 if ANY input is 1 (because 1 ‚â• 1)

![OR gate using MCP neuron](./mcp-or.png)

<Callout variant="example" title="Implementing AND Gate">
  <p>
    Here's how we can implement the OR gate using our MCP neuron:
  </p>
  ```python
weights = [1,1]
threshold = 1
orGate = MCPNeuron(weights,threshold)

inputs = [1,1] # try out other inputs
print(orGate.activate(inputs))
  ```
</Callout>

#### NOT gate (Inhibitor signal)

The NOT gate is particularly interesting because it mirrors how inhibitory signals work in biological neurons. Remember how our bouncer dealt with party-poopers? This is similar!

| Input | Output |
| ----- | ------ |
| 0     | 1      |
| 1     | 0      |

To create a NOT gate using an MCP neuron:

- Give the input a negative weight (-1): üëà this makes it inhibitory
- Set threshold to 0
- When input is 1: (-1 √ó 1) = -1 < 0, output 0
- When input is 0: (-1 √ó 0) = 0 ‚â• 0, output 1

![NOT gate using MCP neuron](./mcp-not.png)

<Callout variant="example" title="Implementing NOT Gate">
  <p>
    Here's how we can implement the NOT gate using our MCP neuron:
  </p>
  ```python
  weights = [-1]
  threshold = 0
  notGate = MCPNeuron(weights,threshold)

  inputs = [1] # try out other inputs
  print(notGate.activate(inputs))
  ```
</Callout>

<Callout variant="exercise" title="Try it yourself!">
- Try designing other logic gates (like <b>NAND</b>, <b>NOR</b>, <b>XOR</b>) using the MCP neuron model.
- Can you find a gate that <b>cannot</b> be implemented with a single MCP neuron? (Hint: **XOR**)
- Think about <b>why</b> some gates work and others don't, what's special about their logic?
- Try chaining multiple MCP neurons to create more complex logic.
</Callout>

### Threshold for biological neurons

In biological neurons, the "threshold" is called **Action Potential** and it's determined by the neuron's properties and the environment.

The threshold can change based on chemicals in the brain, fatigue, or recent activity (for example, after firing a lot, a neuron might temporarily raise its threshold to avoid overloading).

So, in the brain, the threshold is a dynamic property, influenced by genetics, experience, and the neuron's current state.

### Linear Separability

Now to give you a perspective, we can put this 

### Limitations

Even though the MCP neuron was a breakthrough, it comes with some important limitations:

- **No learning or adaptation:** The weights are fixed and must be set manually, so the neuron can't adjust or improve itself based on experience or new data.
- **Works only with simple, linearly separable problems:** It can only handle binary (0/1) signals and can solve logic gates like AND, OR, and NOT, but fails for more complex cases like XOR that can't be separated by a straight line.

This made [Frank Rosenblatt](https://en.wikipedia.org/wiki/Frank_Rosenblatt) think: "How about making the MCP neuron learn?"

## Perceptron

The basic structure is just like the MCP neuron, but here's the big difference: **the weights and threshold can be adjusted through learning!**

### Deriving Perceptron from MCP Neuron (mathematically)

It'll get a bit mathy here, but I promise it'll be worth it.

So we want our neuron to fulfill following conditions:

1. Adjust threshold based on learning (unlike MCP neuron, where threshold and weights are fixed)
2. Adjust weights based on learning

Let's break this down step by step.

#### Step 1: Starting with the MCP Neuron

<Callout variant="proof" title="The Basic MCP Model">
First, let's recall how the MCP neuron works. It has two main components:

1. **Weighted Sum**:
$$
u = \sum_{i=1}^{n} w_i x_i
$$

2. **Activation Function**:
$$
y = \begin{cases} 
  1 & \text{if } u \geq \theta \\
  0 & \text{if } u < \theta
\end{cases}
$$

This model works, but the threshold $\theta$ is fixed. We need to make it learnable.
</Callout>

#### Step 2: Making the Threshold Learnable

<Callout variant="proof" title="Transforming the Threshold">
Let's transform the fixed threshold into something we can learn:

1. First, write out the activation condition:
$$
\sum_{i=1}^{n} w_i x_i \geq \theta
$$

2. Rearrange by subtracting $\theta$ from both sides:
$$
\sum_{i=1}^{n} w_i x_i - \theta \geq 0
$$

3. Here's the key insight: Let's define $b = -\theta$ and call it the **bias**:
$$
\sum_{i=1}^{n} w_i x_i + b \geq 0
$$

This can also be written as:
$$
x_0 b + \sum_{i=1}^{n} w_i x_i \geq 0
$$

where $x_0 = 1$ is a constant input representing the bias. So we are treating it a combination of weight and input.

</Callout>

Now instead of a fixed threshold $\theta$, we have a bias term $b$ as weight that can can be updated based on learning. This is how the perceptron model looks like so far:

![perceptron from mcp neuron](./mcp-to-perceptron-1.png)


#### Step 3: Learning Rule

  By learning we mean, learning by trial and error:

  1. The perceptron makes a prediction based on its current weights
  2. It compares its prediction with the correct answer
  3. If there's an error, it adjusts its weights slightly in the direction that would reduce the error
  4. This process repeats with many examples until the perceptron achieves good accuracy

  Example:
  - For 5+5 if perceptron predicts 9 and correct answer is 10, it will calculate the error and adjust weights to improve next time until it gets the answer right.

  This iterative process of prediction ‚Üí error calculation ‚Üí weight adjustment is what we mean by "learning" and this is what training a perceptron means. It gradually discovers the optimal weights through experience, rather than having them pre-programmed.

<Callout variant="definition" title="The Learning Algorithm">
Now that even bias is a weight, we only need to adjust the weights based on learning.

We'll use the **perceptron learning rule**:

$$
w·µ¢ ‚Üê w·µ¢ + \underbrace{\eta}_{\text{learning rate}} \times \underbrace{(y ‚Äì y')}_{\substack{\text{how wrong}\\\text{we were}}} \times \underbrace{x·µ¢}_{\substack{\text{did input}\\\text{participate?}}}
$$

  <Callout variant="explanation" title="What does this mean?">
    In simple terms:
  
  $new\_weight = \underbrace{old\_weight}_{w_i} + \underbrace{learning\_rate}_{\eta} \times \underbrace{(correct\_answer - prediction)}_{(y - y')} \times \underbrace{input}_{x_i}$
  
  - $w·µ¢$ is the weight of the $i$th input
  - $\eta$ is the learning rate
  - $y$ is the predicted output
  - $y'$ is the correct output
  - $x·µ¢$ is the $i$th input
  </Callout>
</Callout>

#### **What's Learning Rate ($\eta$)?**

Think of it like a tap that controls how fast we adjust the weights:
  
- If learning rate is too high (tap fully open): We make big adjustments and might overshoot the correct weights, like flooding a sink or destroying a settlement if it's a dam üíÄ
- If learning rate is too low (tap barely open): Learning happens very slowly, like filling a swimming pool drop by drop
- Just right (tap opened moderately): We learn steadily without overshooting

For most simple perceptron tasks, a learning rate between 0.1 and 0.01 works well. This gives us enough movement to learn while maintaining stability.

| Learning Rate | Description | Training Behavior |
|--------------|-------------|-------------------|
| 1.0 | High | Quick learning but might overshoot |
| 0.1 | Moderate | Good balance of speed and stability |
| 0.01 | Low | Stable but slow learning |


#### **Why multiply by input ($x_i$)?**

This ensures we only adjust weights that actually contributed to the mistake:
  
  Imagine you're building a dam and notice water leaking. You only want to reinforce the parts where water is actually flowing (input = 1), not the dry parts (input = 0).
  
  - If input was 0: That input didn't contribute to the mistake, so $0 \times anything = 0$ (no adjustment)
  - If input was 1: That input did contribute, so we adjust its weight based on how wrong we were

Idk why I'm obsessed with dams, but it's a fun way to think about it.

<Callout variant="note">
If you notice, since bias has a constant input of $1$, it's weight ($bias$) is updated everytime since it's input is always contributing to the mistake.
</Callout>

Now let's see how the perceptron model looks like now:

![perceptron from mcp neuron](./mcp-to-perceptron-2.png)

### Perceptron convergence theorem

In simple terms, the perceptron convergence theorem states that the perceptron will find a set of weights to solve any linearly separable classification problem. Proving this is a bit out of scope of this post, but you can read more about it in this [medium post](https://medium.com/@adnanemajdoub/perceptron-convergence-theorem-c5b44cc06a08).

### Implementing Perceptron

Let's implement the perceptron model in code.

```python
class Perceptron:
    def __init__(self, learning_rate=0.01):
        self.learning_rate = learning_rate
        self.n_iterations = n_iterations
        self.weights = None
        self.bias = None

        
```

### Activity: Making perceptron learn addition

Let's make perceptron learn addition of two numbers.


### Limitations


## Conclusion

This was a long ass post so I conclude this here. I hope you enjoyed reading this as much as I enjoyed writing it. If you find any mistakes, please let me know.

Thanks for reading :)

