---
title: 'How MCP Neurons and Perceptrons Mirror Real Neurons'
date: 2025-05-10T05:30:47+05:30
draft: false
tags: ['Machine Learning', 'Artificial Intelligence', 'Deep Learning']
description: 'Explore how McCulloch-Pitts neurons and perceptrons work, and see how they compare to real neurons in the brain'
image: './cover.png'
---

import Callout from '@/components/Callout.astro'

> [!NOTE]
> **Neuroscientists:** "It‚Äôs all about synapses and neurotransmitters.‚Äù<br />
> **Engineers:** ‚ÄúFascinating! Can we turn that into code?‚Äù

Fast forward to today, it's everywhere in our lives.

Recently, I picked up the book "How Machines Learn" and found myself captivated by how the earliest artificial neurons like the MCP neuron and the perceptron were designed to mimic real biological neurons (to a certain extent). In this post, I‚Äôll break down how these foundational models work, how closely they mirror the brain, and we'll implement it.

## The Real Deal: Biological Neurons

We all know Neurons are cells found in nevrous system and it's main job is to transmit electrical and chemical signals throughout the body.

![Single Neuron Breakdown](./single-neuron-breakdown.png)

### How do neurons work?

1. **Dendrites**: these are like thoundands of tiny antennas, each receive signals from other neurons

2. **Signals**: these are electrochemical signals and one thing to note is each signal has it's importance meaning one signal can be less important than other. Signals can be excitatory (encouraging the neuron to fire) or inhibitory (discouraging it)

3. **Cell body/Soma**: All the incoming signals gather up at the body and it decides whether to fire the signal or not. If the combines importance of the excitatory signal minus the inhibitroy signal exceeds this threshold -> Boom the neuron fires.

4. **Axon & Terminals**: This is like a dedicated output cable, carrying the decision. Axon terminals are like broadcast stations, sending the signal to dendrites of other neurons

### Neuron working analogy

![bar analogy for neuron's working](./bar-analogy.png)

Think of it like a bar with the world's most mathematical bouncer. Let's break down how this party (I mean, neuron ;) works:

1. Every person (signal) has a specific importance value (weight)
2. Normal people count as 1
3. VIPs count as 2 (they're twice as important!)
4. Police/party-poopers count as -2 (they actually work against the party starting)
5. The party only starts when the total "party value" hits a certain threshold

#### **The Basic Party Math**

![bar analogy for neuron's working](./bar-analogy-1.png)

When just one regular person shows up (value = 1), and the threshold is > 1, no party happens. But when two regular people arrive (1 + 1 = 2), boom! We hit the threshold, and the party (neuron) activates!

#### **When Things Get Interesting**

![bar analogy for neuron's working](./bar-analogy-2.png)

Now this is where our bouncer's math gets spicy (just like real-world drama):

**Scene 1**: Two regular college buddies show up $(1 + 1)$, but wait... who's that rolling up in a Mercedes? Oh snap, it's the minister's son and his influencial friend $(VIP = 2)$! Total party value hits $6$ and Party mode: ACTIVATED! üéâ

**Scene 2**: A police officer $(-2)$ shows up after getting noise complaints. But lucky for us, we've got our the minister's son and his equally influential friend $(2 + 2)$.
Even with Officer Party-Pooper, the vibe stays alive because $4 > threshold$.

Diplomatic immunity for the win! (He pulled off an _'Janta hai mera baap kon hai?'_)

**Scene 3**: Plot twist! Turns out he was just pretending to be a minister's son.

Three real police officers $(-2 √ó 3 = -6)$. Even with our regular squad and the influential friend $(total positive = 6)$, the party gets shut down faster than he can say "My dad will hear about this!" Because $6 - 6 = 0 < 4$

Moral of the story? Just like neurons, it's all about balance - and maybe don't lie about being a minister's kid! üòÖ

Just like this bouncer, a neuron:

- Adds up excitatory signals (party people)
- Subtracts inhibitory signals (police)
- Only "fires" (starts the party) when the total hits the threshold
- Stays quiet (no party) when it doesn't

![mcp meme](./mcp-meme.png)

Well that's what McCulloch Pitts Neuron (MCP) Neuron does. It's a super simplified binary version of a real neuron. Read more about the [limitations and differences](#limitations-and-differences) below.

## McCulloch Pitts Neuron (MCP)

![McCulloch Pitts Neuron explained](./mcp-breakdown.png)

Here is how it works:

1. Takes weighted inputs and sums them up
2. Passes weighted sum to the **activation function**
3. Activation function based on threshold produces binary output $1$ or $0$

> Why binary output?
>
> Because back then due to limited understanding of neurons, scientists were under the assumption that neurons were in two state: **Fires** or **Doesn't fire**.
>
> Now we know that Neurons produces spectrum of outputs and there are a lot more elements involved into it and we have more advanced models of neurons.

### Activation function

An activation function is like a decision-maker for a neuron, like the Soma (cell body).

It takes total signal a neuron receives (after adding all of the weighted inputs) and determines what the output should be, which is usually transformed into something useful like 0 or 1, or a number between 0 and 1.

The MCP neuron uses **Step Function** i.e it returns binary output based on the input meeting the given a threshold $Œ∏(theta)$ criteria.

$y$ being the output of the activation function and $u$ being input (total signal/weighted sum) or in other terms $u$ is the output of the weighted sum function.

```math
{\displaystyle y={\begin{cases}1&{\text{if }}u\geq \theta \\0&{\text{if }}u<\theta \end{cases}}}
```

<Callout title="Intuition" variant="intuition">
  <p>
    If you get anxious seeing such mathy fonts, here's a flow diagram to help build intuition:
  </p>

  ![step function flow diagram](./step-function-diagram.png)

</Callout>

This is also used in [perceptron](#perceptron) as we'll discuss further. But the question is what can we do with it?

### Implementing MCP Neuron

Let's implement it in code. We'll use Python to create a simple implementation of the MCP neuron.


<Callout title="Python Implementation: MCP Neuron" variant="example">
  <p>
    This class takes a list of weights and a threshold, computes the weighted sum of the inputs, and applies a step activation function:
  </p>
  ```python
  class MCPNeuron:
      def __init__(self, weights, theta):
          self.weights = weights
          self.theta = theta

      def weighted_sum(self, inputs):
          return sum(i * w for i, w in zip(inputs, self.weights))

      def step_function(self, u):
          return int(u >= self.theta)  # returns 1 if threshold met, else 0

      def activate(self, inputs):
          u = self.weighted_sum(inputs)
          return self.step_function(u)
  ```
</Callout>


### Implementing Logic Gates using MCP

Why are we suddenly talking about logic gates? Well, it turns out MCP neurons can do something pretty neat: they can simulate basic logical operations. This was one of the first practical applications that got researchers excited.

Just by choosing different weights and thresholds, we can make it perform logical operations. Let's see how:

#### The AND Gate

First, let's look at the AND operation:

| Input 1 | Input 2 | Output |
| ------- | ------- | ------ |
| 0       | 0       | 0      |
| 0       | 1       | 0      |
| 1       | 0       | 0      |
| 1       | 1       | 1      |

To make an MCP neuron behave like an AND gate:

- Give both inputs a weight of 1
- Set threshold to 2
- This way, we only get output 1 when BOTH inputs are 1 (1 + 1 ‚â• 2)

![and gate using MCP neuron](./mcp-and.png)

<Callout variant="example" title="Implementing AND Gate">
  <p>
    Here's how we can implement the AND gate using our MCP neuron:
  </p>
  ```python
weights = [1,1]
threshold = 2
andGate = MCPNeuron(weights,threshold)

inputs = [1,1] # try out other inputs
print(andGate.activate(inputs))
  ```
</Callout>

#### The OR Gate

The OR operation outputs true if ANY input is true:

| Input 1 | Input 2 | Output |
| ------- | ------- | ------ |
| 0       | 0       | 0      |
| 0       | 1       | 1      |
| 1       | 0       | 1      |
| 1       | 1       | 1      |

To create an OR gate:

- Keep weights at 1 each
- Lower threshold to 1
- Now we get output 1 if ANY input is 1 (because 1 ‚â• 1)

![OR gate using MCP neuron](./mcp-or.png)

<Callout variant="example" title="Implementing AND Gate">
  <p>
    Here's how we can implement the OR gate using our MCP neuron:
  </p>
  ```python
weights = [1,1]
threshold = 1
orGate = MCPNeuron(weights,threshold)

inputs = [1,1] # try out other inputs
print(orGate.activate(inputs))
  ```
</Callout>

#### NOT gate (Inhibitor signal)

The NOT gate is particularly interesting because it mirrors how inhibitory signals work in biological neurons. Remember how our bouncer dealt with party-poopers? This is similar!

| Input | Output |
| ----- | ------ |
| 0     | 1      |
| 1     | 0      |

To create a NOT gate using an MCP neuron:

- Give the input a negative weight (-1): üëà this makes it inhibitory
- Set threshold to 0
- When input is 1: (-1 √ó 1) = -1 < 0, output 0
- When input is 0: (-1 √ó 0) = 0 ‚â• 0, output 1

![NOT gate using MCP neuron](./mcp-not.png)

<Callout variant="example" title="Implementing NOT Gate">
  <p>
    Here's how we can implement the NOT gate using our MCP neuron:
  </p>
  ```python
  weights = [-1]
  threshold = 0
  notGate = MCPNeuron(weights,threshold)

  inputs = [1] # try out other inputs
  print(notGate.activate(inputs))
  ```
</Callout>

<Callout variant="exercise" title="Try it yourself!">
- Try designing other logic gates (like <b>NAND</b>, <b>NOR</b>, <b>XOR</b>) using the MCP neuron model.
- Can you find a gate that <b>cannot</b> be implemented with a single MCP neuron? (Hint: **XOR**)
- Think about <b>why</b> some gates work and others don't, what's special about their logic?
- Try chaining multiple MCP neurons to create more complex logic.
</Callout>

### Threshold for biological neurons

In biological neurons, the "threshold" is called **Action Potential** and it's determined by the neuron's properties and the environment.

The threshold can change based on chemicals in the brain, fatigue, or recent activity (for example, after firing a lot, a neuron might temporarily raise its threshold to avoid overloading).

So, in the brain, the threshold is a dynamic property, influenced by genetics, experience, and the neuron's current state.

### Limitations

Even though the MCP neuron was a breakthrough, it comes with some important limitations:

- **No learning or adaptation:** The weights are fixed and must be set manually, so the neuron can't adjust or improve itself based on experience or new data.
- **Works only with simple, linearly separable problems:** It can only handle binary (0/1) signals and can solve logic gates like AND, OR, and NOT, but fails for more complex cases like XOR that can't be separated by a straight line.

This made [Frank Rosenblatt](https://en.wikipedia.org/wiki/Frank_Rosenblatt) think: "How about making the MCP neuron learn?"

## Perceptron

The basic structure is just like the MCP neuron, but here's the big difference: **the weights can now be adjusted through learning!**

<Callout variant="explanation" title="What do we mean by learning?">
  **Learning through trial and error**:

  1. The perceptron makes a prediction based on its current weights
  2. It compares its prediction with the correct answer
  3. If there's an error, it adjusts its weights slightly in the direction that would reduce the error
  4. This process repeats with many examples until the perceptron achieves good accuracy

  Example:
  - For 5+5 if perceptron predicts 9 and correct answer is 10, it will calculate the error and adjust weights to improve next time until it gets the answer right.

  This iterative process of prediction ‚Üí error calculation ‚Üí weight adjustment is what we mean by "learning" and this is what training a perceptron means. It gradually discovers the optimal weights through experience, rather than having them pre-programmed.
</Callout>

Here's the simple but powerful learning rule:

<Callout variant="notation" title="Perceptron Learning Rule">
  
$$
  w·µ¢ ‚Üê w·µ¢ + \underbrace{\eta}_{\text{learning rate}} \times \underbrace{(y ‚Äì y')}_{\substack{\text{how wrong}\\\text{we were}}} \times \underbrace{x·µ¢}_{\substack{\text{did input}\\\text{participate?}}}
$$

  <Callout variant="explanation" title="What does this mean?">
    In simple terms:
  
  $new\_weight = \underbrace{old\_weight}_{w_i} + \underbrace{learning\_rate}_{\eta} \times \underbrace{(correct\_answer - prediction)}_{(y - y')} \times \underbrace{input}_{x_i}$
  
  - $w·µ¢$ is the weight of the $i$th input
  - $\eta$ is the learning rate
  - $y$ is the predicted output
  - $y'$ is the correct output
  - $x·µ¢$ is the $i$th input
  </Callout>
</Callout>


### **What's Learning Rate ($\eta$)?**

Think of it like a tap that controls how fast we adjust the weights:
  
- If learning rate is too high (tap fully open): We make big adjustments and might overshoot the correct weights, like flooding a sink or destroying a settlement if it's a dam üíÄ
- If learning rate is too low (tap barely open): Learning happens very slowly, like filling a swimming pool drop by drop
- Just right (tap opened moderately): We learn steadily without overshooting

For most simple perceptron tasks, a learning rate between 0.1 and 0.01 works well. This gives us enough movement to learn while maintaining stability.

| Learning Rate | Description | Training Behavior |
|--------------|-------------|-------------------|
| 1.0 | High | Quick learning but might overshoot |
| 0.1 | Moderate | Good balance of speed and stability |
| 0.01 | Low | Stable but slow learning |


### **Why multiply by input ($x_i$)?**

This ensures we only adjust weights that actually contributed to the mistake:
  
  Imagine you're building a dam and notice water leaking. You only want to reinforce the parts where water is actually flowing (input = 1), not the dry parts (input = 0).
  
  - If input was 0: That input didn't contribute to the mistake, so $0 \times anything = 0$ (no adjustment)
  - If input was 1: That input did contribute, so we adjust its weight based on how wrong we were

### Perceptron convergence theorem

### Implementing Perceptron

### Activity: Making perceptron learn addition

Let's make perceptron learn addition of two numbers.

### Perceptron as a Linear Classifier

### How do neurons learn?

### Limitations

